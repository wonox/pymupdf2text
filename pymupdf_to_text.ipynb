{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新コーディングマニュアル\n",
    "\n",
    "https://contents.nii.ac.jp/korekara/about/sw_wg/pc202402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM0\n"
     ]
    }
   ],
   "source": [
    "import fitz # import PyMuPDF\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# テキストを置換：項目名を△△で囲む\n",
    "def text_replace(text):\n",
    "\n",
    "   # text = re.sub(r'\\n([^\\d\\.|^[A-Z])', r'\\1', text)  # 不要な改行の削除\n",
    "   # text = re.sub(r'( [A-Z][0-9])', r'\\1', text)\n",
    "   text = re.sub(r'\\n([\\d\\.]{2,}[A-Z]*)', r'\\n△\\1△', text)\n",
    "   text = re.sub(r'^([\\d\\.]{2,})', r'\\n△\\1△', text) # △0.1△ \n",
    "   text = re.sub(r'([^A-Z][A-Z]\\d[\\.\\d]*)', r'\\n△\\1△', text) # △B2.2△  \n",
    "   text = re.sub(r'→ \\n△(.+)△', r'→\\1', text) # (→ \\n△\n",
    "   text = re.sub(r' \\n△(.+)△ (から)\\n△(.+)△', r'\\1\\2\\3', text)\n",
    "   text = re.sub(r'^(第.+?章)', r'\\1△', text)\n",
    "   text = re.sub(r'△(\\d\\d\\d)△', r'\\1', text)\n",
    "   text = re.sub(r'△([^A-B0-9\\.].+)△', r'\\1', text)\n",
    "   return text\n",
    "\n",
    "# pymupdfでPDFをテキストに変換\n",
    "def pdf2text(filepath):\n",
    "   basename_without_ext = os.path.splitext(os.path.basename(filepath))[0]\n",
    "   print(basename_without_ext)\n",
    "\n",
    "   doc = fitz.open(filepath)  # open a supported document\n",
    "\n",
    "   text = \"\"\n",
    "   # text = chr(12).join([page.get_text() for page in doc])\n",
    "   text = \"\".join([page.get_text() for page in doc])\n",
    "   text = text_replace(text)\n",
    "   return text, basename_without_ext\n",
    "\n",
    "# テキストをDataFrameに変換\n",
    "def text2df(text):\n",
    "   # split()で文字列を分割して取得したリストにstrip()を適用する。\n",
    "   # 空白を含むカンマ区切り文字列の余分な空白を除去してリスト内包表記でリスト化\n",
    "   # list_text = [x.strip() for x in text[0].split('△')]\n",
    "   list_text = [x.strip() for x in text.split('△')]\n",
    "   list_text = [a for a in list_text if a != '']  # 内包表記で空の要素を駆逐する\n",
    "   # print(list_text)\n",
    "\n",
    "   # キーとバリューが交互に並ぶリストを辞書にする\n",
    "   dict_text = dict(zip(list_text[0::2], list_text[1::2]))\n",
    "   #print(dict_text)\n",
    "\n",
    "   # 異なる長さのリストを含む辞書をpd.DataFrameに変換\n",
    "   df2 = pd.DataFrame.from_dict(dict_text, orient='index')\n",
    "   # df2\n",
    "   df2.to_excel('pndas_to_excel.xlsx', sheet_name='new_sheet_name')\n",
    "   return df2\n",
    "\n",
    "\n",
    "filepath = r\"pdf/CM0.pdf\"\n",
    "text = pdf2text(filepath)\n",
    "# 戻り値の型はタプルとなる。text, basename_without_ext\n",
    "dataframe = text2df(text[0])\n",
    "\n",
    "# path_w = r\"cm0.txt\"\n",
    "other_filepath = os.path.join(os.path.dirname(filepath), text[1]) # basename_without_ext)\n",
    "other_ext_filepath = other_filepath + '.txt'\n",
    "\n",
    "with open(other_ext_filepath, mode='w') as f:\n",
    "    f.write(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>データセット</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1A</th>\n",
       "      <td>〔通則〕 \\n 総合目録データベースのデータセット構成は、大きくは図書と雑誌に分かれ、それぞ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.1</th>\n",
       "      <td>図書と逐次刊行物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.1A</th>\n",
       "      <td>〔通則〕 \\n 当該資料が、図書であるか逐次刊行物であるかの区分は、原則として，資料の刊行方...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.2</th>\n",
       "      <td>和資料と洋資料 \\n 総合目録データベースのデータセット上は、和資料と洋資料の区別はない。「...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.2A</th>\n",
       "      <td>〔通則〕 \\n資料が和資料であるか洋資料であるかは、原則として、規定の情報源に表示されたタイ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.2B</th>\n",
       "      <td>(選択事項) \\n 音楽資料を登録する場合、以下の規定に従い、和資料か洋資料かを選択する。 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.2C</th>\n",
       "      <td>〔例〕 \\nタイトルも本文も日本語の場合(和図書資料) \\n \\nTTLL:jpn TXTL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1.2D</th>\n",
       "      <td>《注意事項》 \\n\\nD1 \\n 本項に定める通り、データ登録の際には、準拠すべき目録規則に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>新規データ作成の指針</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4A</th>\n",
       "      <td>〔通則〕 \\n 目録対象資料にかかわるデータ登録に際しては、0.4.1～0.4.6 に示され...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4B</th>\n",
       "      <td>〔既存データの使用〕 \\n 既存データが目録対象資料に対応すると認められる場合は、当該データ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4C</th>\n",
       "      <td>〔新規データの作成〕 \\n 既存データが目録対象資料に対応すると認められない場合は、新規デー...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4D</th>\n",
       "      <td>(選択事項) \\n\\nD1 \\n 目録対象資料に対応する参照データが存在する場合、当該データ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4E</th>\n",
       "      <td>《注意事項》 \\n\\nE1 \\n 原則として既存データが目録対象資料に対応すると認められる場...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.1</th>\n",
       "      <td>図書書誌データ \\n 図書書誌データセットへの出版物理単位のデータ登録に際しては、以下の指針...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.1A</th>\n",
       "      <td>〔通則〕 \\n\\nA1 \\n 既存データのデータ内容が、次の条件のうち少なくとも1 つを満た...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.1B</th>\n",
       "      <td>〔新規データ作成の判断基準〕 \\n\\nB1 〔GMD/SMD〕 \\n GMD フィールド及び...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.1C</th>\n",
       "      <td>《注意事項》 \\n\\nC1 \\n 対応関係の最終的な確認は、当該既存データ全体及び当該目録対...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.2</th>\n",
       "      <td>図書書誌データ(親書誌) \\n 図書書誌データセットへの集合書誌単位のデータの登録及び書誌構...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.2A</th>\n",
       "      <td>〔通則〕 \\n  既存の書誌データを使用するか、新規に書誌データを作成するかは、タイトルや出...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.2B</th>\n",
       "      <td>〔新規データ作成の判断基準〕 \\n\\nB1 〔GMD/SMD〕 \\n  既存の書誌データにつ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.3</th>\n",
       "      <td>雑誌書誌データ \\n 雑誌データセットへの書誌データの新規登録に際しては、以下の指針に従って...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.3A</th>\n",
       "      <td>[通則] \\n\\nA1 \\n 目録対象資料と既存書誌データの内容を比較し、本タイトルが異なる...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.3B</th>\n",
       "      <td>[新規データ作成の判断基準] \\n\\nB1 [GMD／SMD](資料種別) \\n (原則) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.4</th>\n",
       "      <td>著者名典拠データ \\n 著者名典拠データセットへのデータ登録に際しては、以下の指針にしたがっ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.4A</th>\n",
       "      <td>〔通則〕 \\n 既存の著者名典拠データと目録対象資料の著者の典拠形アクセス・ポイントとが、対...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4.4B</th>\n",
       "      <td>〔新規データ作成の判断基準〕 \\n\\nB1 〔HDNG〕 \\n\\nB1.1 (優先名称) \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0.1                                                データセット\n",
       "0.1A    〔通則〕 \\n 総合目録データベースのデータセット構成は、大きくは図書と雑誌に分かれ、それぞ...\n",
       "0.1.1                                            図書と逐次刊行物\n",
       "0.1.1A  〔通則〕 \\n 当該資料が、図書であるか逐次刊行物であるかの区分は、原則として，資料の刊行方...\n",
       "0.1.2   和資料と洋資料 \\n 総合目録データベースのデータセット上は、和資料と洋資料の区別はない。「...\n",
       "0.1.2A  〔通則〕 \\n資料が和資料であるか洋資料であるかは、原則として、規定の情報源に表示されたタイ...\n",
       "0.1.2B  (選択事項) \\n 音楽資料を登録する場合、以下の規定に従い、和資料か洋資料かを選択する。 ...\n",
       "0.1.2C  〔例〕 \\nタイトルも本文も日本語の場合(和図書資料) \\n \\nTTLL:jpn TXTL...\n",
       "0.1.2D  《注意事項》 \\n\\nD1 \\n 本項に定める通り、データ登録の際には、準拠すべき目録規則に...\n",
       "0.4                                            新規データ作成の指針\n",
       "0.4A    〔通則〕 \\n 目録対象資料にかかわるデータ登録に際しては、0.4.1～0.4.6 に示され...\n",
       "0.4B    〔既存データの使用〕 \\n 既存データが目録対象資料に対応すると認められる場合は、当該データ...\n",
       "0.4C    〔新規データの作成〕 \\n 既存データが目録対象資料に対応すると認められない場合は、新規デー...\n",
       "0.4D    (選択事項) \\n\\nD1 \\n 目録対象資料に対応する参照データが存在する場合、当該データ...\n",
       "0.4E    《注意事項》 \\n\\nE1 \\n 原則として既存データが目録対象資料に対応すると認められる場...\n",
       "0.4.1   図書書誌データ \\n 図書書誌データセットへの出版物理単位のデータ登録に際しては、以下の指針...\n",
       "0.4.1A  〔通則〕 \\n\\nA1 \\n 既存データのデータ内容が、次の条件のうち少なくとも1 つを満た...\n",
       "0.4.1B  〔新規データ作成の判断基準〕 \\n\\nB1 〔GMD/SMD〕 \\n GMD フィールド及び...\n",
       "0.4.1C  《注意事項》 \\n\\nC1 \\n 対応関係の最終的な確認は、当該既存データ全体及び当該目録対...\n",
       "0.4.2   図書書誌データ(親書誌) \\n 図書書誌データセットへの集合書誌単位のデータの登録及び書誌構...\n",
       "0.4.2A  〔通則〕 \\n  既存の書誌データを使用するか、新規に書誌データを作成するかは、タイトルや出...\n",
       "0.4.2B  〔新規データ作成の判断基準〕 \\n\\nB1 〔GMD/SMD〕 \\n  既存の書誌データにつ...\n",
       "0.4.3   雑誌書誌データ \\n 雑誌データセットへの書誌データの新規登録に際しては、以下の指針に従って...\n",
       "0.4.3A  [通則] \\n\\nA1 \\n 目録対象資料と既存書誌データの内容を比較し、本タイトルが異なる...\n",
       "0.4.3B  [新規データ作成の判断基準] \\n\\nB1 [GMD／SMD](資料種別) \\n (原則) ...\n",
       "0.4.4   著者名典拠データ \\n 著者名典拠データセットへのデータ登録に際しては、以下の指針にしたがっ...\n",
       "0.4.4A  〔通則〕 \\n 既存の著者名典拠データと目録対象資料の著者の典拠形アクセス・ポイントとが、対...\n",
       "0.4.4B  〔新規データ作成の判断基準〕 \\n\\nB1 〔HDNG〕 \\n\\nB1.1 (優先名称) \\..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdf\\\\CM0.pdf']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob(\"pdf/*.pdf\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'目録システムコーディングマニュアル（CAT2020対応版）\\n[]\\n[]改訂履歴\\n[]0.1.1 図書と逐次刊行物\\n0.1 データセット\\n0.1A 〔通則〕\\n総合目録データベースのデータセット構成は、大きくは図書と雑誌に分かれ、それぞれ書誌データセットと所蔵データセットが中心となっている。さらに、典拠コントロールを行うための著者名典拠データセット、統一書名典拠データセットがあり、これら全体で総合目録データベースを形成している。\\n総合目録データベースの外周には参照データセットがある。参照データセットとは、外部機関作成データを目録システム用に変換したものである。\\nデータセット構成及び各データセットの詳細については、「目録情報の基準 第5版」（2.1 データセット構成）を参照のこと。\\n[]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://qiita.com/poorko/items/9140c75415d748633a10\n",
    "# Pythonのスクレイピングで文字だけを抜き出す汎用的な方法\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# urlを指定してBeautifulSoupオブジェクトを返す\n",
    "def scrape_html(url):\n",
    "  html = requests.get( url ) # .text\n",
    "  soup = BeautifulSoup(html.content.decode(\"utf-8\", \"ignore\"), \"html.parser\")\n",
    "  # print(soup.prettify)\n",
    "  return soup\n",
    "\n",
    "# BeautifulSoupオブジェクトを引数に、テキストを返す\n",
    "def get_text(soup):\n",
    "  # scriptやstyleを含む要素を削除(decompose)する  head と link<a>も抜く\n",
    "  for script in soup([\"script\",  \"style\", \"head\", \"a\"]):\n",
    "      script.decompose()\n",
    "  # print(soup)\n",
    "  # タグを削除してテキストを取得\n",
    "  text = soup.get_text()\n",
    "  # print(text)\n",
    "  # textを改行ごとにリストに入れて、リスト内の要素の前後の空白を削除(strip)、内包表記でリスト化\n",
    "  lines = [line.strip() for line in text.splitlines()]\n",
    "  #lines = []\n",
    "  # for line in text.splitlines():\n",
    "  #  lines.append(line.strip())\n",
    "  # print(lines)\n",
    "\n",
    "  text = \"\\n\".join(line for line in lines if line)\n",
    "  # print(text)\n",
    "  return text\n",
    "\n",
    "# URLを引数に、リンクのリストを出力\n",
    "def list_links(url):\n",
    "    parse_html = scrape_html(url)\n",
    "    title_lists = parse_html.find_all(\"a\")\n",
    "\n",
    "    # hrefを取得してリスト化\n",
    "    name_list = []\n",
    "    url_list = []\n",
    "    for i in title_lists:\n",
    "        name_list.append(i.string)\n",
    "        url_list.append(i.get('href'))   # (i.attrs[\"href\"]) getはなければNoneが返ってきます\n",
    "\n",
    "    # リストの空の要素を消す\n",
    "    # [x for x in url_list if x != '']\n",
    "    url_list_b = [x for x in url_list if x is not None]\n",
    "    # 外だし：先頭が数字のリンクを抽出し、リスト化\n",
    "    # url_list_b = [x for x in url_list_b if re.match('^\\d', x)]\n",
    "    # print(url_list_b)\n",
    "    \n",
    "    return url_list_b\n",
    "\n",
    "# URLを引数にurlをパースして、リンクのリストを返す\n",
    "def url_parse(access_url):\n",
    "   parsed_url = urlparse(access_url) \n",
    "   path_list = parsed_url.path.split(\"/\")[-2:]\n",
    "   # フォーマットする \n",
    "   # url = '{uri.scheme}://{uri.netloc}/path_list[0]/'.format(uri=urlparse(access_url))\n",
    "   url_d = parsed_url.scheme + '://' + parsed_url.netloc + '/' + path_list[0] + '/'\n",
    "   print(url_d)\n",
    "\n",
    "   # リンク先をリスト化\n",
    "   url_list_b = list_links(access_url)\n",
    "   # url_full = url_d + url_list_b[0]\n",
    "   # htmlファイルをスクレイプする\n",
    "   # print(scrape_html(url_d + url_list_b[0])) #.decode(\"utf-8\")\n",
    "   # html_text = get_text(scrape_html(url_full))\n",
    "\n",
    "   # urlのリストから、url_fullをリスト化\n",
    "   url_full = [url_d + i for i in url_list_b]\n",
    "   \"\"\"\n",
    "   url_full = []\n",
    "   for i in url_list_b:\n",
    "      url_full.append(url_d + i)\n",
    "      # html_text += get_text(scrape_html(url_full))\n",
    "   \"\"\"\n",
    "   return url_full\n",
    "\n",
    "# テスト用\n",
    "get_text(scrape_html(\"https://catill.bitbucket.io/CM/0_1.html\")) ##https://qiita.com/poorko/items/9140c75415d748633a10\"))\n",
    "# list_links(\"https://catill.bitbucket.io/CM/mokuji.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 旧（現行）CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://catill.bitbucket.io/CM/\n"
     ]
    }
   ],
   "source": [
    "access_url = \"https://catill.bitbucket.io/CM/mokuji.html\"\n",
    "url_full = url_parse(access_url)\n",
    "\n",
    "# 外だし：先頭が数字のリンクを抽出し、リスト化\n",
    "#url_full = [x for x in url_full if re.match('^\\d', x)]\n",
    "\n",
    "# print(url_full)\n",
    "html_text = \"\"\n",
    "for i in url_full:\n",
    "    html_text += get_text(scrape_html(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 外だし：先頭が数字のリンクを抽出し、リスト化\n",
    "url_full = [x for x in url_full if re.match('^\\d', x)]\n",
    "print(url_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_w = 'text/cm_old.txt'\n",
    "\n",
    "with open(path_w, mode='w') as f:\n",
    "    f.write(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text2df22(text):\n",
    "   # split()で文字列を分割して取得したリストにstrip()を適用する。\n",
    "   # 空白を含むカンマ区切り文字列の余分な空白を除去してリスト内包表記でリスト化\n",
    "   # list_text = [x.strip() for x in text[0].split('△')]\n",
    "   list_text = [x.strip() for x in text.split('△')]\n",
    "   list_text = [a for a in list_text if a != '']  # 内包表記で空の要素を駆逐する\n",
    "   print(list_text)\n",
    "\n",
    "   # キーとバリューが交互に並ぶリストを辞書にする\n",
    "   dict_text = dict(zip(list_text[0::2], list_text[1::2]))\n",
    "   print(dict_text)\n",
    "\n",
    "   # 異なる長さのリストを含む辞書をpd.DataFrameに変換\n",
    "   df2 = pd.DataFrame.from_dict(dict_text, orient='index')\n",
    "   df2\n",
    "   df2.to_excel('pndas_to_excel.xlsx', sheet_name='new_sheet_name')\n",
    "   return df2\n",
    "\n",
    "# テキストを置換：項目名を△△で囲む\n",
    "def text_replace22(text):\n",
    "\n",
    "   # text = re.sub(r'\\n([^\\d\\.|^[A-Z])', r'\\1', text)  # 不要な改行の削除\n",
    "   text = re.sub(r'目録システムコーディングマニュアル（CAT2020対応版）\\n', r'', text)\n",
    "   text = re.sub(r'\\n([\\d\\.]{2,}[A-Z]*)', r'\\n△\\1△', text)\n",
    "   text = re.sub(r'^([\\d\\.]{2,})', r'\\n△\\1△', text) # △0.1△ \n",
    "   text = re.sub(r'([^A-Z][A-Z]\\d[\\.\\d]*)', r'\\n△\\1△', text) # △B2.2△  \n",
    "   text = re.sub(r'→ \\n△(.+)△', r'→\\1', text) # (→ \\n△\n",
    "   text = re.sub(r' \\n△(.+)△ (から)\\n△(.+)△', r'\\1\\2\\3', text)\n",
    "   text = re.sub(r'^(第.+?章)', r'\\1△', text)\n",
    "   text = re.sub(r'△(\\d\\d\\d)△', r'\\1', text)\n",
    "   text = re.sub(r'\\[.+', r'', text)\n",
    "   return text\n",
    "\n",
    "text2df22(text_replace22(html_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
